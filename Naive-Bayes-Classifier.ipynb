{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sympy\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Overview of the basics\n",
    "For a random variable $x$, $P(x)$ is a function that assigns a probability to all values of $x$.\n",
    "\n",
    "- Probability Density of $x = P(x)$\n",
    "\n",
    "The probability of a specific event A for a random variable x is denoted as P(x=A), or simply as P(A).\n",
    "\n",
    "- Probability of Event $A = P(A)$\n",
    "\n",
    "Probability is calculated as the number of desired outcomes divided by the total possible outcomes, in the case where all outcomes are equally likely.\n",
    "\n",
    "- Probability = ${\\large \\frac{number-of-desired-outcomes}{total-number-of-possible-outcomes}}$\n",
    "\n",
    ">This is intuitive if we think about a discrete random variable such as the roll of a dice. For example, the probability of a dice rolling a 5 is calculated as one outcome of rolling a 5 (1) divided by the total number of discrete outcomes (6) or 1/6 or about 0.1666 or about 16.666%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of taking 2 red ball(s) is: 8.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08695652173913043"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is a simple preview of probability calculator\n",
    "def probability(desired_outcomes, total_outcomes):\n",
    "    probability = desired_outcomes / total_outcomes\n",
    "    \n",
    "    if desired_outcomes == 12:\n",
    "        color = \"green\"\n",
    "    elif desired_outcomes == 8:\n",
    "        color = \"blue\"\n",
    "    elif desired_outcomes == 2:\n",
    "        color = \"red\"\n",
    "    elif desired_outcomes == total_outcomes:\n",
    "        color = \"(all)\"\n",
    "    else:\n",
    "        color = \"yellow\"\n",
    "  \n",
    "    print(f\"The probability of taking {desired_outcomes} {color} ball(s) is:\", str(round(probability*100, 2))+\"%\")\n",
    "    return probability # Probability is a number between 0 and 1. 1 Denoting 100% and 0 denoting 0%\n",
    "\n",
    "# Let's say we have 12 Green balls, 8 blue balls, 2 red balls and 1 yellow ball\n",
    "# What is the probability of reaching and taking 1 yellow ball?\n",
    "\n",
    "total_balls = 12 + 8 + 2 + 1\n",
    "desired_balls = 2 # Play around with this variable to see how different portions react\n",
    "\n",
    "probability(desired_balls, total_balls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of the probabilities of all outcomes must equal one. If not, we do not have valid probabilities.\n",
    "\n",
    "- Sum of the Probabilities for All Outcomes = 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of taking 12 green ball(s) is: 52.17%\n",
      "The probability of taking 8 blue ball(s) is: 34.78%\n",
      "The probability of taking 2 red ball(s) is: 8.7%\n",
      "The probability of taking 1 yellow ball(s) is: 4.35%\n",
      "Sum of all probabilities: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "green_balls = 12\n",
    "blue_balls = 8\n",
    "red_balls = 2\n",
    "yellow_balls = 1\n",
    "\n",
    "total_sum = probability(green_balls, total_balls) + probability(blue_balls,total_balls) + probability(red_balls,total_balls)+ probability(yellow_balls,total_balls) \n",
    "\n",
    "print(\"Sum of all probabilities:\", total_sum*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of an impossible outcome is zero. For example, it is impossible to roll a 7 with a standard six-sided die.\n",
    "\n",
    "- Probability of Impossible Outcome = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of a certain outcome is one. For example, it is certain that a value between 1 and 6 will occur when rolling a six-sided die.\n",
    "\n",
    "- Probability of Certain Outcome = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of taking 23 (all) ball(s) is: 100.0%\n",
      "Probability of certain outcome: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability of certain outcome:\", probability(total_balls, total_balls)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of an event not occurring, called the complement.\n",
    "\n",
    "This can be calculated by one minus the probability of the event, or 1 – P(A). For example, the probability of not rolling a 5 would be 1 – P(5) or 1 – 0.166 or about 0.833 or about 83.333%.\n",
    "\n",
    "- Probability of Not Event $A = 1 – P(A)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of taking 12 green ball(s) is: 52.17%\n",
      "Probability of Not Event: 47.83 %\n"
     ]
    }
   ],
   "source": [
    "# Lets take the probability of 12 green balls\n",
    "green_balls = 12\n",
    "draw_probability = probability(green_balls, total_balls)\n",
    "\n",
    "print(\"Probability of Not Event:\", str(round((1 - draw_probability)*100, 2)), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem of Conditional Probability\n",
    "Before we dive into Bayes theorem, let’s review marginal, joint, and conditional probability.\n",
    "\n",
    "Recall that marginal probability is the probability of an event, irrespective of other random variables. If the random variable is independent, then it is the probability of the event directly, otherwise, if the variable is dependent upon other variables, then the marginal probability is the probability of the event summed over all outcomes for the dependent variables, called the sum rule.\n",
    "\n",
    "- **Marginal Probability**: The probability of an event irrespective of the outcomes of other random variables, e.g. $P(A)$.\n",
    "\n",
    "The joint probability is the probability of two (or more) simultaneous events, often described in terms of events A and B from two dependent random variables, e.g. X and Y. The joint probability is often summarized as just the outcomes, e.g. A and B.\n",
    "\n",
    "- **Joint Probability**: Probability of two (or more) simultaneous events, e.g. $P(A and B)$ or $P(A, B)$.\n",
    "\n",
    "The conditional probability is the probability of one event given the occurrence of another event, often described in terms of events A and B from two dependent random variables e.g. X and Y.\n",
    "\n",
    "- **Conditional Probability**: Probability of one (or more) event given the occurrence of another event, e.g. $P(A given B)$ or $P(A | B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint probability distribution\n",
    "Now let's see what happens if we roll two dice. For each die, the outcomes are associated with a certain probability. We need two random variables to describe the game, let's say that $\\text{x}$ corresponds to the first die and $\\text{y}$ to the second one. We also have two probability mass functions associated with the random variables: $P(\\text{x})$ and $P(\\text{y})$. Here the possible values of the random variables (1, 2, 3, 4, 5 or 6) and the probability mass functions are actually the same for both dice, but it doesn't need to be the case.\n",
    "\n",
    "The joint probability distribution is useful in the cases where we are interested in the probability that $\\text{x}$ takes a specific value while $\\text{y}$ takes another specific value. For instance, what would be the probability to get a 1 with the first dice and 2 with the second dice? The probabilities corresponding to every pair of values are written $P(\\text{x}=x, \\text{y}=y)$ or $P(\\text{x}, \\text{y})$. This is what we call the joint probability.\n",
    "\n",
    "### Example 1.\n",
    "\n",
    "For example, let's calculate the probability to have a 1 with the first dice and a 2 in the second:\n",
    "\n",
    "$$\n",
    "P(\\text{x}=1, \\text{y}=2) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36} \\approx 0.028\n",
    "$$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability is the probability of one event given the occurrence of another event, often described in terms of events A and B from two dependent random variables e.g. $X$ and $Y$.\n",
    "\n",
    "- Conditional Probability: Probability of one (or more) event given the occurrence of another event, e.g. $P(A given B)$ or $P(A | B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint probability can be calculated using the conditional probability; for example:\n",
    "\n",
    "- $P(A, B) = P(A | B) * P(B)$\n",
    "\n",
    "This is called the product rule. Importantly, the joint probability is symmetrical, meaning that:\n",
    "\n",
    "- $P(A, B) = P(B, A)$\n",
    "\n",
    "The conditional probability can be calculated using the joint probability; for example:\n",
    "\n",
    "- $P(A | B) = P(A, B) / P(B)$\n",
    "\n",
    "The conditional probability is not symmetrical; for example:\n",
    "\n",
    "- $P(A | B) != P(B | A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Naive Bayes algorithm?\n",
    "\n",
    "   It is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n",
    "\n",
    "   For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.\n",
    "\n",
    "   Naive Bayes model is easy to build and particularly useful for very large data sets. Along with simplicity, Naive Bayes is known to outperform even highly sophisticated classification methods.\n",
    "\n",
    "   Bayes theorem provides a way of calculating posterior probability $P(c|x)$ from $P(c)$, $P(x)$ and $P(x|c)$. Look at the equation below:\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\\begin{align}\n",
    "{\\large P(c|x) = \\frac{P(x|c)P(c)}{P(x)}}\n",
    "\\end{align}\n",
    "\n",
    "<br>\n",
    "\n",
    "## Naming the Terms in the Theorem\n",
    "The terms in the Bayes Theorem equation are given names depending on the context where the equation is used.\n",
    "\n",
    "Firstly, in general, the result $P(A|B)$ is referred to as the **posterior probability** and $P(A$) is referred to as the **prior probability**.\n",
    "\n",
    "- $P(A|B)$: Posterior probability.\n",
    "- $P(A)$: Prior probability.\n",
    "\n",
    "Sometimes $P(B|A)$ is referred to as the **likelihood** and $P(B)$ is referred to as the **evidence**.\n",
    "\n",
    "- $P(B|A)$: Likelihood.\n",
    "- $P(B)$: Evidence.\n",
    "\n",
    "This allows Bayes Theorem to be restated as:\n",
    "\n",
    "- **Posterior = Likelihood * Prior / Evidence**\n",
    "\n",
    "We can make this clear with a smoke and fire case.\n",
    "\n",
    "What is the probability that there is fire given that there is smoke?\n",
    "\n",
    "Where P(Fire) is the Prior, P(Smoke|Fire) is the Likelihood, and P(Smoke) is the evidence:\n",
    "\n",
    "- $P(Fire|Smoke)$ = $P(Smoke|Fire)$ * $P(Fire) / P(Smoke)$\n",
    "\n",
    "You can imagine the same situation with rain and clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Test Scenario\n",
    "An excellent and widely used example of the benefit of Bayes Theorem is in the analysis of a medical diagnostic test.\n",
    "\n",
    "Scenario: Consider a human population that may or may not have cancer (Cancer is True or False) and a medical test that returns positive or negative for detecting cancer (Test is Positive or Negative), e.g. like a mammogram for detecting breast cancer.\n",
    "\n",
    ">Problem: If a randomly selected patient has the test and it comes back positive, what is the probability that the patient has cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Calculation\n",
    "Medical diagnostic tests are not perfect; they have **error**.\n",
    "\n",
    "Sometimes a patient will have cancer, but the test will not detect it. This capability of the test to detect cancer is referred to as the sensitivity, or the **true positive rate**.\n",
    "\n",
    "In this case, we will contrive a sensitivity value for the test. The test is good, but not great, with a true positive rate or sensitivity of $85%$. That is, of all the people who have cancer and are tested, $85%$ of them will get a positive result from the test.\n",
    "\n",
    "- $P(Test=Positive | Cancer=True) = 0.85$\n",
    "\n",
    "Given this information, our intuition would suggest that there is an 85% probability that the patient has cancer.\n",
    "\n",
    "**Our intuitions of probability are wrong.**\n",
    "\n",
    "This type of error in interpreting probabilities is so common that it has its own name; it is referred to as the **base rate fallacy**.\n",
    "\n",
    "It has this name because the error in estimating the probability of an event is caused by ignoring the base rate. That is, it ignores the probability of a randomly selected person having cancer, regardless of the results of a diagnostic test.\n",
    "\n",
    "In this case, we can assume the probability of breast cancer is low, and use a contrived base rate value of one person in 5,000, or (0.0002) 0.02%.\n",
    "\n",
    "- $P(Cancer=True) = 0.02%$.\n",
    "\n",
    "We can correctly calculate the probability of a patient having cancer given a positive test result using Bayes Theorem.\n",
    "\n",
    "Let’s map our scenario onto the equation:\n",
    "\n",
    "- $P(A|B) = P(B|A) * P(A) / P(B)$\n",
    "\n",
    "- $P(Cancer=True | Test=Positive)$ = $P(Test=Positive|Cancer=True)$ * $P(Cancer=True)$ / $P(Test=Positive)$\n",
    "\n",
    "We know the probability of the test being positive given that the patient has cancer is 85%, and we know the base rate or the prior probability of a given patient having cancer is 0.02%; we can plug these values in:\n",
    "\n",
    "- $P(Cancer=True | Test=Positive)$ = 0.85 * 0.0002 / $P(Test=Positive)$\n",
    "\n",
    "We **don’t know** $P(Test=Positive)$, it’s not given directly.\n",
    "\n",
    "Instead, we can estimate it using:\n",
    "\n",
    "- $P(B)$ = $P(B|A)$ * $P(A)$ + $P(B|not A)$ * $P(not A)$\n",
    "\n",
    "- $P(Test=Positive)$ = $P(Test=Positive|Cancer=True)$ * $P(Cancer=True)$ + $P(Test=Positive|Cancer=False)$ * $P(Cancer=False)$\n",
    "\n",
    "Firstly, we can calculate $P(Cancer=False)$ as the complement of $P(Cancer=True)$, which we already know\n",
    "\n",
    "- $P(Cancer=False)$ = 1 – $P(Cancer=True)$\n",
    "- = 1 – 0.0002\n",
    "- = 0.9998\n",
    "\n",
    "Let’s plugin what we have:\n",
    "\n",
    "We can plug in our known values as follows:\n",
    "\n",
    "- $P(Test=Positive)$ = 0.85 * 0.0002 + $P(Test=Positive|Cancer=False)$ * 0.9998\n",
    "\n",
    "We still do not know the probability of a positive test result given no cancer.\n",
    "\n",
    "This requires additional information.\n",
    "\n",
    "Specifically, we need to know how good the test is at correctly identifying people that do not have cancer. That is, testing negative result (Test=Negative) when the patient does not have cancer (Cancer=False), called the true negative rate or the specificity.\n",
    "\n",
    "We will use a contrived specificity value of 95%.\n",
    "\n",
    "- $P(Test=Negative | Cancer=False)$ = 0.95\n",
    "\n",
    "With this final piece of information, we can calculate the false positive or false alarm rate as the complement of the true negative rate.\n",
    "\n",
    "P(Test=Positive|Cancer=False) = 1 – P(Test=Negative | Cancer=False)\n",
    "= 1 – 0.95\n",
    "= 0.05\n",
    "We can plug this false alarm rate into our calculation of P(Test=Positive) as follows:\n",
    "\n",
    "P(Test=Positive) = 0.85 * 0.0002 + 0.05 * 0.9998\n",
    "P(Test=Positive) = 0.00017 + 0.04999\n",
    "P(Test=Positive) = 0.05016\n",
    "Excellent, so the probability of the test returning a positive result, regardless of whether the person has cancer or not is about 5%.\n",
    "\n",
    "We now have enough information to calculate Bayes Theorem and estimate the probability of a randomly selected person having cancer if they get a positive test result.\n",
    "\n",
    "P(Cancer=True | Test=Positive) = P(Test=Positive|Cancer=True) * P(Cancer=True) / P(Test=Positive)\n",
    "P(Cancer=True | Test=Positive) = 0.85 * 0.0002 / 0.05016\n",
    "P(Cancer=True | Test=Positive) = 0.00017 / 0.05016\n",
    "P(Cancer=True | Test=Positive) = 0.003389154704944\n",
    "The calculation suggests that if the patient is informed they have cancer with this test, then there is only 0.33% chance that they have cancer.\n",
    "\n",
    "It is a terrible diagnostic test!\n",
    "\n",
    "The example also shows that the calculation of the conditional probability requires enough information.\n",
    "\n",
    "For example, if we have the values used in Bayes Theorem already, we can use them directly.\n",
    "\n",
    "This is rarely the case, and we typically have to calculate the bits we need and plug them in, as we did in this case. In our scenario we were given 3 pieces of information, the the base rate, the  sensitivity (or true positive rate), and the specificity (or true negative rate).\n",
    "\n",
    "Sensitivity: 85% of people with cancer will get a positive test result.\n",
    "Base Rate: 0.02% of people have cancer.\n",
    "Specificity: 95% of people without cancer will get a negative test result.\n",
    "We did not have the P(Test=Positive), but we calculated it given what we already had available.\n",
    "\n",
    "We might imagine that Bayes Theorem allows us to be even more precise about a given scenario. For example, if we had more information about the patient (e.g. their age) and about the domain (e.g. cancer rates for age ranges), and in turn we could offer an even more accurate probability estimate.\n",
    "\n",
    "That was a lot of work.\n",
    "\n",
    "Let’s look at how we can calculate this exact scenario using a few lines of Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
